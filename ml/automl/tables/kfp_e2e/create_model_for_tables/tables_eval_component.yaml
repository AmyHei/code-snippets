name: Automl eval tables model
inputs:
- name: gcp_project_id
  type: String
- name: gcp_region
  type: String
- name: model_display_name
  type: String
- name: bucket_name
  type: String
- name: gcs_path
  type: String
- name: api_endpoint
  type: String
  optional: true
outputs:
- name: eval_data
  type: evals
- name: mlpipeline_ui_metadata
  type: UI_metadata
- name: feat_list
  type: String
implementation:
  container:
    image: python:3.7
    command:
    - python3
    - -u
    - -c
    - |
      def _make_parent_dirs_and_return_path(file_path: str):
          import os
          os.makedirs(os.path.dirname(file_path), exist_ok=True)
          return file_path

      class OutputPath:
          '''When creating component from function, OutputPath should be used as function parameter annotation to tell the system that the function wants to output data by writing it into a file with the given path instead of returning the data from the function.'''
          def __init__(self, type=None):
              self.type = type

      from typing import NamedTuple

      def automl_eval_tables_model(
        gcp_project_id: str,
        gcp_region: str,
        model_display_name: str,
        bucket_name: str,
        gcs_path: str,
        eval_data_path: OutputPath('evals'),
        mlpipeline_ui_metadata_path: OutputPath('UI_metadata'),
        api_endpoint: str = None,

      ) -> NamedTuple('Outputs', [
          ('feat_list', str)]):
        import subprocess
        import sys
        # we could build a base image that includes these libraries if we don't want to do
        # the dynamic installation when the step runs.
        subprocess.run([sys.executable, '-m', 'pip', 'install', 'googleapis-common-protos==1.6.0',
           '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'}, check=True)
        subprocess.run([sys.executable, '-m', 'pip', 'install', 'google-cloud-automl==0.9.0',
           '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'}, check=True)
        subprocess.run([sys.executable, '-m', 'pip', 'install',
           'matplotlib', 'pathlib2', 'google-cloud-storage',
           '--no-warn-script-location'], env={'PIP_DISABLE_PIP_VERSION_CHECK': '1'}, check=True)

        import google
        import json
        import logging
        import pickle
        import pathlib2

        from google.api_core.client_options import ClientOptions
        from google.api_core import exceptions
        from google.cloud import automl_v1beta1 as automl
        from google.cloud.automl_v1beta1 import enums
        from google.cloud import storage

        def upload_blob(bucket_name, source_file_name, destination_blob_name,
            public_url=False):
          """Uploads a file to the bucket."""

          storage_client = storage.Client()
          bucket = storage_client.bucket(bucket_name)
          blob = bucket.blob(destination_blob_name)

          blob.upload_from_filename(source_file_name)

          logging.info("File {} uploaded to {}.".format(
                  source_file_name, destination_blob_name))
          if public_url:
            blob.make_public()
            logging.info("Blob {} is publicly accessible at {}".format(
                    blob.name, blob.public_url))
          return blob.public_url

        def get_model_details(client, model_display_name):
          try:
            model = client.get_model(model_display_name=model_display_name)
          except exceptions.NotFound:
            logging.info("Model %s not found." % model_display_name)
            return (None, None)

          model = client.get_model(model_display_name=model_display_name)
          # Retrieve deployment state.
          if model.deployment_state == enums.Model.DeploymentState.DEPLOYED:
            deployment_state = "deployed"
          else:
            deployment_state = "undeployed"
          # get features of top global importance
          feat_list = [
              (column.feature_importance, column.column_display_name)
              for column in model.tables_model_metadata.tables_model_column_info
          ]
          feat_list.sort(reverse=True)
          if len(feat_list) < 10:
            feat_to_show = len(feat_list)
          else:
            feat_to_show = 10

          # Log some information about the model
          logging.info("Model name: {}".format(model.name))
          logging.info("Model id: {}".format(model.name.split("/")[-1]))
          logging.info("Model display name: {}".format(model.display_name))
          logging.info("Features of top importance:")
          for feat in feat_list[:feat_to_show]:
            logging.info(feat)
          logging.info("Model create time:")
          logging.info("\tseconds: {}".format(model.create_time.seconds))
          logging.info("\tnanos: {}".format(model.create_time.nanos))
          logging.info("Model deployment state: {}".format(deployment_state))

          generate_fi_ui(feat_list)
          return (model, feat_list)

        def generate_fi_ui(feat_list):
          import matplotlib.pyplot as plt

          image_suffix = '{}/gfi.png'.format(gcs_path)
          res = list(zip(*feat_list))
          x = list(res[0])
          y = list(res[1])
          y_pos = list(range(len(y)))
          plt.figure(figsize=(10, 6))
          plt.barh(y_pos, x, alpha=0.5)
          plt.yticks(y_pos, y)
          plt.savefig('/gfi.png')
          public_url = upload_blob(bucket_name, '/gfi.png', image_suffix, public_url=True)
          logging.info('using image url {}'.format(public_url))

          html_suffix = '{}/gfi.html'.format(gcs_path)
          with open('/gfi.html', 'w') as f:
            f.write('<html><head></head><body><h1>Global Feature Importance</h1>\n<img src="{}" width="97%"/></body></html>'.format(public_url))
          upload_blob(bucket_name, '/gfi.html', html_suffix)
          html_source = 'gs://{}/{}'.format(bucket_name, html_suffix)
          logging.info('metadata html source: {}'.format(html_source))

          metadata = {
            'outputs' : [
            {
              'type': 'web-app',
              'storage': 'gcs',
              'source': html_source
            }]}
          logging.info('using metadata dict {}'.format(json.dumps(metadata)))
          logging.info('using metadata ui path: {}'.format(mlpipeline_ui_metadata_path))
          with open(mlpipeline_ui_metadata_path, 'w') as mlpipeline_ui_metadata_file:
            mlpipeline_ui_metadata_file.write(json.dumps(metadata))

        logging.getLogger().setLevel(logging.INFO)  # TODO: make level configurable
        # TODO: we could instead check for region 'eu' and use 'eu-automl.googleapis.com:443'endpoint
        # in that case, instead of requiring endpoint to be specified.
        if api_endpoint:
          client_options = ClientOptions(api_endpoint=api_endpoint)
          client = automl.TablesClient(project=gcp_project_id, region=gcp_region,
              client_options=client_options)
        else:
          client = automl.TablesClient(project=gcp_project_id, region=gcp_region)

        (model, feat_list) = get_model_details(client, model_display_name)

        evals = list(client.list_model_evaluations(model_display_name=model_display_name))
        with open('temp_oput_regression', "w") as f:
          f.write('Model evals:\n{}'.format(evals))
        pstring = pickle.dumps(evals)

        # write to eval_data_path
        if eval_data_path:
          logging.info("eval_data_path: %s", eval_data_path)
          try:
            pathlib2.Path(eval_data_path).parent.mkdir(parents=True)
          except FileExistsError:
            pass
          pathlib2.Path(eval_data_path).write_bytes(pstring)

        feat_list_string = json.dumps(feat_list)
        return feat_list_string

      def _serialize_str(str_value: str) -> str:
          if not isinstance(str_value, str):
              raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
          return str_value

      import argparse
      _parser = argparse.ArgumentParser(prog='Automl eval tables model', description='')
      _parser.add_argument("--gcp-project-id", dest="gcp_project_id", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--gcp-region", dest="gcp_region", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--model-display-name", dest="model_display_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--bucket-name", dest="bucket_name", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--gcs-path", dest="gcs_path", type=str, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--api-endpoint", dest="api_endpoint", type=str, required=False, default=argparse.SUPPRESS)
      _parser.add_argument("--eval-data", dest="eval_data_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("--mlpipeline-ui-metadata", dest="mlpipeline_ui_metadata_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
      _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
      _parsed_args = vars(_parser.parse_args())
      _output_files = _parsed_args.pop("_output_paths", [])

      _outputs = automl_eval_tables_model(**_parsed_args)

      if not hasattr(_outputs, '__getitem__') or isinstance(_outputs, str):
          _outputs = [_outputs]

      _output_serializers = [
          _serialize_str,

      ]

      import os
      for idx, output_file in enumerate(_output_files):
          try:
              os.makedirs(os.path.dirname(output_file))
          except OSError:
              pass
          with open(output_file, 'w') as f:
              f.write(_output_serializers[idx](_outputs[idx]))
    args:
    - --gcp-project-id
    - inputValue: gcp_project_id
    - --gcp-region
    - inputValue: gcp_region
    - --model-display-name
    - inputValue: model_display_name
    - --bucket-name
    - inputValue: bucket_name
    - --gcs-path
    - inputValue: gcs_path
    - if:
        cond:
          isPresent: api_endpoint
        then:
        - --api-endpoint
        - inputValue: api_endpoint
    - --eval-data
    - outputPath: eval_data
    - --mlpipeline-ui-metadata
    - outputPath: mlpipeline_ui_metadata
    - '----output-paths'
    - outputPath: feat_list
