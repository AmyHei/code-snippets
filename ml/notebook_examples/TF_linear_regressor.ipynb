{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. All Rights Reserved.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate some noisy training and test data. (based on Jake's example on day 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomponents = 1\n",
    "slopes_true = np.random.uniform(0, 1, ncomponents)\n",
    "intercepts_true = np.random.uniform(0, 1, ncomponents)\n",
    "component_fractionalprobs = np.random.dirichlet(np.arange(1., ncomponents+1.))\n",
    "print('Slopes:', slopes_true)\n",
    "print('Intercepts:', intercepts_true)\n",
    "print('Fractional probabilities:', component_fractionalprobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndatapoints = 100\n",
    "ndatapoints_test = 20\n",
    "\n",
    "xis_true = np.random.uniform(0, 1, ndatapoints)\n",
    "xis_test_true = np.random.uniform(0, 1, ndatapoints_test)\n",
    "x_grid = np.linspace(0, 1, 100)\n",
    "\n",
    "numberpercomponent = np.random.multinomial(ndatapoints, component_fractionalprobs)\n",
    "numberpercomponent_test = np.random.multinomial(ndatapoints_test, component_fractionalprobs)\n",
    "allocations = np.concatenate([np.repeat(i, nb).astype(int) \n",
    "                              for i, nb in enumerate(numberpercomponent)])\n",
    "allocations_test = np.concatenate([np.repeat(i, nb).astype(int) \n",
    "                              for i, nb in enumerate(numberpercomponent_test)])\n",
    "np.random.shuffle(allocations)\n",
    "np.random.shuffle(allocations_test)\n",
    "\n",
    "\n",
    "def model_linear(xs, slope, intercept): return xs * slope + intercept\n",
    "yis_true = model_linear(xis_true, slopes_true[allocations], intercepts_true[allocations])\n",
    "yis_test_true = model_linear(xis_test_true, slopes_true[allocations_test], intercepts_true[allocations_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma_yis = np.repeat(0.1, ndatapoints) * np.random.uniform(0.5, 2.0, ndatapoints)\n",
    "yis_noisy = yis_true + np.random.randn(ndatapoints) * sigma_yis\n",
    "\n",
    "sigma_yis_test = np.repeat(0.1, ndatapoints_test) * np.random.uniform(0.5, 2.0, ndatapoints_test)\n",
    "yis_test_noisy = yis_test_true + np.random.randn(ndatapoints_test) * sigma_yis_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning the TensorFlow part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a utility function for generating a new directory in which to save \n",
    "# model information, so multiple training runs don't stomp on each other.\n",
    "def get_new_path(name=\"\"):\n",
    "    base=\"/tmp/tfmodels/linear\"\n",
    "    logpath = os.path.join(base, name + \"_\" + str(int(time.time())))\n",
    "    print(\"Logging to {}\".format(logpath))\n",
    "    return logpath\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# linear classification, and many neural network classifiers and regressors.\n",
    "# The following code provides an estimator that does linear regression.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns, model_dir=get_new_path('lr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "\n",
    "# x_train = np.array([1., 2., 3., 4.])\n",
    "# y_train = np.array([0., -1., -2., -3.])\n",
    "# x_eval = np.array([2., 5., 8., 1.])\n",
    "# y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "x_train = xis_true\n",
    "y_train = yis_noisy\n",
    "x_eval = xis_test_true\n",
    "y_eval = yis_test_true\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "estimator.train(input_fn=input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {

 },
 "nbformat": 4,
 "nbformat_minor": 2
}
